{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocesamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para cargar una imagen y su máscara\n",
    "def load_image_and_mask(image_path, mask_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    mask = Image.open(mask_path)\n",
    "    return np.array(image), np.array(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, size=(256, 256)):\n",
    "    return np.array(Image.fromarray(image).resize(size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    # Redimensionar la imagen\n",
    "    resized_image = resize_image(image)\n",
    "    # Normalizar los píxeles de la imagen\n",
    "    normalized_image = resized_image.astype('float32') / 255.0\n",
    "    return normalized_image\n",
    "\n",
    "def preprocess_mask(mask, num_classes):\n",
    "    # Redimensionar la máscara\n",
    "    resized_mask = resize_image(mask)\n",
    "    # Asegurarse de que los valores de la máscara sean enteros\n",
    "    resized_mask = resized_mask.astype(np.int32)\n",
    "    # Asegurarse de que los valores de la máscara estén dentro del rango de clases\n",
    "    resized_mask[resized_mask >= num_classes] = num_classes - 1\n",
    "    return resized_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio que contiene las imágenes y las máscaras\n",
    "images_dir = '../RGB/images/'\n",
    "masks_dir = '../RGB/masks/'\n",
    "\n",
    "# Preprocesamiento de las imágenes\n",
    "preprocessed_images = []\n",
    "preprocessed_masks = []\n",
    "\n",
    "# Recorrer todas las imágenes y máscaras\n",
    "for image_file in os.listdir(images_dir):\n",
    "    if image_file.endswith('.tif'):\n",
    "        image_path = os.path.join(images_dir, image_file)\n",
    "        mask_file = image_file.replace('.tif', '.tif')\n",
    "        mask_path = os.path.join(masks_dir, mask_file)\n",
    "        \n",
    "        # Cargar la imagen y la máscara\n",
    "        image, mask = load_image_and_mask(image_path, mask_path)\n",
    "        \n",
    "        # Preprocesar la imagen y la máscara\n",
    "        preprocessed_image = preprocess_image(image)\n",
    "        preprocessed_mask = preprocess_mask(mask, num_classes=5)\n",
    "                \n",
    "        # Agregar la imagen y la máscara preprocesadas\n",
    "        preprocessed_images.append(preprocessed_image)\n",
    "        preprocessed_masks.append(preprocessed_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de imágenes: 36\n",
      "Número de máscaras: 36\n",
      "Tamaño de las imágenes: (256, 256, 3)\n",
      "Tamaño de las máscaras: (256, 256)\n"
     ]
    }
   ],
   "source": [
    "print('Número de imágenes:', len(preprocessed_images))\n",
    "print('Número de máscaras:', len(preprocessed_masks))\n",
    "\n",
    "print('Tamaño de las imágenes:', preprocessed_images[0].shape)\n",
    "print('Tamaño de las máscaras:', preprocessed_masks[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de imágenes de entrenamiento: 28\n",
      "Número de imágenes de validación: 8\n",
      "Tamaño de las imágenes: (256, 256, 3)\n",
      "Tamaño de las máscaras: (256, 256)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convertir las listas a arrays numpy\n",
    "preprocessed_images = np.array(preprocessed_images)\n",
    "preprocessed_masks = np.array(preprocessed_masks)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(preprocessed_images, preprocessed_masks, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Imprimir información sobre los conjuntos\n",
    "print('Número de imágenes de entrenamiento:', len(X_train))\n",
    "print('Número de imágenes de validación:', len(X_val))\n",
    "print('Tamaño de las imágenes:', X_train[0].shape)\n",
    "print('Tamaño de las máscaras:', y_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "#imprimimos los valor unicos de las mascaras\n",
    "\n",
    "print(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate\n",
    "import numpy as np\n",
    "\n",
    "def unet_model(input_shape=(256, 256, 3), num_classes=5):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # Codificación (downsampling)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    # Capa central\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
    "\n",
    "    # Decodificación (upsampling)\n",
    "    up6 = Conv2DTranspose(512, 2, strides=(2, 2), padding='same')(conv5)\n",
    "    up6 = concatenate([up6, conv4], axis=3)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = Conv2DTranspose(256, 2, strides=(2, 2), padding='same')(conv6)\n",
    "    up7 = concatenate([up7, conv3], axis=3)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(conv7)\n",
    "    up8 = concatenate([up8, conv2], axis=3)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(conv8)\n",
    "    up9 = concatenate([up9, conv1], axis=3)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
    "\n",
    "    # Capa de salida\n",
    "    outputs = Conv2D(num_classes, 1, activation='softmax')(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Define el número de clases\n",
    "num_classes = 5\n",
    "\n",
    "# Construir el modelo\n",
    "model = unet_model(input_shape=(256, 256, 3), num_classes=num_classes)\n",
    "\n",
    "# Compilar el modelo con clases desbalanceadas\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 29s/step - accuracy: 0.1618 - loss: 1.5996 - val_accuracy: 0.2846 - val_loss: 1.4154\n",
      "Epoch 2/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 63s/step - accuracy: 0.4472 - loss: 1.4273 - val_accuracy: 0.6188 - val_loss: 1.1856\n",
      "Epoch 3/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 32s/step - accuracy: 0.4696 - loss: 1.2962 - val_accuracy: 0.6204 - val_loss: 1.1652\n",
      "Epoch 4/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 55s/step - accuracy: 0.4592 - loss: 1.2849 - val_accuracy: 0.6204 - val_loss: 1.0333\n",
      "Epoch 5/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 46s/step - accuracy: 0.4601 - loss: 1.2155 - val_accuracy: 0.6203 - val_loss: 1.0218\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=16,\n",
    "    epochs=5,\n",
    "    validation_data=(X_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo en el conjunto de validación\n",
    "evaluation = model.evaluate(X_val, y_val)\n",
    "\n",
    "# Obtener las métricas de evaluación\n",
    "loss = evaluation[0]\n",
    "accuracy = evaluation[1]\n",
    "\n",
    "# Imprimir las métricas de evaluación\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Obtener las predicciones del modelo en el conjunto de validación\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Calcular F1-Score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Convertir las máscaras de las predicciones y los datos de validación a un formato adecuado\n",
    "\n",
    "y_pred_argmax = np.argmax(y_pred, axis=3)\n",
    "y_val_argmax = y_val\n",
    "\n",
    "# Calcular el F1-Score\n",
    "\n",
    "f1 = f1_score(y_val_argmax.flatten(), y_pred_argmax.flatten(), average='weighted')\n",
    "\n",
    "# Imprimir el F1-Score\n",
    "\n",
    "print(\"F1-Score:\", f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Definir colores para las clases\n",
    "colors = [[0, 0, 0],    # Negro, probablemente áreas con poca vegetación o sin\n",
    "          [255, 0, 0],  # Rojo, probablemente para edificaciones\n",
    "          [0, 255, 0],  # Verde, probablemente para vegetación\n",
    "          [0, 0, 255],  # Azul, probablemente agua\n",
    "          [255, 255, 255]]  # Blanco, probablemente caminos\n",
    "\n",
    "# Función para convertir la máscara a una imagen colorida\n",
    "def mask_to_colored_image(mask, colors):\n",
    "    height, width = mask.shape\n",
    "    colored_image = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    for class_id, color in enumerate(colors):\n",
    "        colored_image[mask == class_id] = color\n",
    "    return colored_image\n",
    "\n",
    "# Función para visualizar las imágenes, máscaras y predicciones\n",
    "def display_results(X_val, y_val, y_pred, num_images=5):\n",
    "    plt.figure(figsize=(15, num_images * 5))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        # Imagen de entrada\n",
    "        plt.subplot(num_images, 3, i * 3 + 1)\n",
    "        plt.title('Imagen de entrada')\n",
    "        plt.imshow(X_val[i])\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Máscara verdadera\n",
    "        plt.subplot(num_images, 3, i * 3 + 2)\n",
    "        plt.title('Máscara verdadera')\n",
    "        y_val_colored = mask_to_colored_image(np.argmax(y_val[i], axis=-1), colors)\n",
    "        plt.imshow(y_val_colored)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Predicción del modelo\n",
    "        plt.subplot(num_images, 3, i * 3 + 3)\n",
    "        plt.title('Predicción del modelo')\n",
    "        y_pred_colored = mask_to_colored_image(y_pred[i], colors)\n",
    "        plt.imshow(y_pred_colored)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualizar los resultados\n",
    "display_results(X_val, y_val, y_pred_classes, num_images=9)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
